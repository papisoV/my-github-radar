import requests
import datetime
import os
import json
import urllib.parse

# --- 1. é…ç½®åŒº ---
FEISHU_WEBHOOK = os.getenv('FEISHU_WEBHOOK')
DB_FILE = "pushed_ids.txt"
HISTORY_FILE = "stars_history.json"
GITHUB_TOKEN = os.getenv('GITHUB_TOKEN') 

BLACK_LIST = ["awesome", "roadmap", "interview", "collection", "guide", "free-courses"]
FAMOUS_ORGS = ["vercel", "openai", "anthropic", "meta", "google", "microsoft", "bytedance", "alibaba", "xai-org", "nvidia", "cloudflare"]
GROWTH_THRESHOLD = 50  # çˆ†å‘é˜ˆå€¼

# --- 2. æ ¸å¿ƒåŠŸèƒ½å‡½æ•° ---

def get_owner_fame(owner_name):
    """è¯†åˆ« Owner æ˜¯å¦æ˜¯å¤§ä½¬æˆ–å¤§å‚"""
    if owner_name.lower() in FAMOUS_ORGS:
        return "ğŸ¢ å¤§å‚å®˜å·"
    if GITHUB_TOKEN:
        try:
            headers = {"Authorization": f"token {GITHUB_TOKEN}"}
            user_url = f"https://api.github.com/users/{owner_name}/repos?sort=stars&per_page=1"
            res = requests.get(user_url, headers=headers, timeout=5).json()
            if isinstance(res, list) and len(res) > 0:
                if res[0]['stargazers_count'] > 10000:
                    return "ğŸ‘‘ å¤§ä½¬å›å½’"
        except: pass
    return ""

def get_smart_tags(item):
    """æ ¹æ®æè¿°è¯†åˆ«æŠ€æœ¯æ ‡ç­¾"""
    name_desc = (item['full_name'] + (item['description'] or "")).lower()
    tags = []
    if item['language']: tags.append(f"ğŸ·ï¸{item['language']}")
    topics = {
        "ğŸ¤– AI/ML": ["llm", "ai", "gpt", "claude", "agent", "rag", "inference", "stable-diffusion"],
        "ğŸŒ Web": ["react", "vue", "typescript", "tailwind", "nextjs", "browser"],
        "âš™ï¸ Tooling": ["cli", "workflow", "automation", "scripts"],
        "ğŸ¦€ Performance": ["rust", "performance", "blazing", "cuda", "cpp"],
        "â˜ï¸ DevOps": ["docker", "k8s", "aws", "serverless", "cloudflare"]
    }
    for tag, keywords in topics.items():
        if any(key in name_desc for key in keywords): tags.append(tag)
    return " ".join(tags[:3])

def translate_to_zh(text):
    if not text: return "æ— æè¿°"
    try:
        base_url = "https://translate.googleapis.com/translate_a/single?client=gtx&sl=en&tl=zh-CN&dt=t&q="
        res = requests.get(base_url + urllib.parse.quote(text), timeout=5)
        return "".join([i[0] for i in res.json()[0]])
    except: return text

def get_hn_context(full_name):
    """è·¨ç•Œæƒ…æŠ¥ï¼šæœç´¢ Hacker News è®¨è®º"""
    try:
        # ä½¿ç”¨é¡¹ç›®åæœç´¢ HN
        query_name = full_name.split('/')[-1]
        hn_api = f"https://hn.algolia.com/api/v1/search?query={query_name}&tags=story"
        res = requests.get(hn_api, timeout=5).json()
        if res['nbHits'] > 0:
            top = res['hits'][0]
            return {
                "url": f"https://news.ycombinator.com/item?id={top['objectID']}",
                "comments": top.get('num_comments', 0),
                "points": top.get('points', 0)
            }
    except: pass
    return None

# --- 3. æ•°æ®åŠ è½½ ---
now = datetime.datetime.utcnow() + datetime.timedelta(hours=8)
now_str = now.strftime('%Y-%m-%d %H:%M:%S')

pushed_ids = set()
if os.path.exists(DB_FILE):
    with open(DB_FILE, "r") as f:
        pushed_ids = set(line.strip() for line in f if line.strip())

stars_history = {}
if os.path.exists(HISTORY_FILE):
    with open(HISTORY_FILE, "r") as f:
        try: stars_history = json.load(f)
        except: stars_history = {}

# --- 4. æŠ“å–ä¸å¤„ç† ---
start_date = (now - datetime.timedelta(days=30)).strftime('%Y-%m-%d')
query = f"created:>{start_date} stars:>500 fork:false"
url = f"https://api.github.com/search/repositories?q={query}&sort=stars&order=desc"

try:
    headers = {"Authorization": f"token {GITHUB_TOKEN}"} if GITHUB_TOKEN else {}
    items = requests.get(url, headers=headers).json().get('items', [])
    if not items: exit(0)

    current_stars_map = {}
    qualified_items = []
    
    for i in items:
        if any(word in (i['full_name']+(i['description'] or "")).lower() for word in BLACK_LIST): continue

        # æ´»è·ƒåº¦è¿‡æ»¤
        pushed_at = datetime.datetime.strptime(i['pushed_at'], '%Y-%m-%dT%H:%M:%SZ') + datetime.timedelta(hours=8)
        if (now - pushed_at).total_seconds() > 48 * 3600: continue
            
        item_id = str(i['id'])
        current_stars = i['stargazers_count']
        current_stars_map[item_id] = current_stars
        
        # è®¡ç®—å¢é•¿
        base_growth = current_stars - stars_history.get(item_id, current_stars)
        i['raw_growth'] = base_growth
        i['hour_growth'] = base_growth 
        
        # è¯†åˆ«ç”»åƒ
        fame_tag = get_owner_fame(i['owner']['login'])
        i['fame_tag'] = fame_tag
        i['smart_tags'] = (f"{fame_tag} " if fame_tag else "") + get_smart_tags(i)
        
        # --- è·¨ç•Œè”åŠ¨é€»è¾‘ ---
        i['hn_info'] = None
        if base_growth > 30 or fame_tag:
            i['hn_info'] = get_hn_context(i['full_name'])
            if i['hn_info'] and i['hn_info']['comments'] > 10:
                i['hour_growth'] += 2000 # æå®¢çƒ­è®®å¤§å¹…åŠ æƒ
                i['smart_tags'] += " ğŸ”¥æå®¢çƒ­è®®"

        # æœ€ç»ˆæƒé‡åˆ†é…
        if fame_tag: i['hour_growth'] += 10000 
        elif current_stars > 10000 and base_growth > 30: i['hour_growth'] += 500
        
        qualified_items.append(i)

    # æ’åº
    sorted_items = sorted(qualified_items, key=lambda x: x['hour_growth'], reverse=True)
    explosive_items = [i for i in sorted_items if i['raw_growth'] >= GROWTH_THRESHOLD or (i['fame_tag'] and i['raw_growth'] > 20)]
    new_items = [i for i in sorted_items if str(i['id']) not in pushed_ids]

    # --- 5. README æ„é€  ---
    md_content = f"# ğŸŒŠ GitHub æŠ€æœ¯æš—æµé›·è¾¾\n\n> ğŸ•’ æ›´æ–°: {now_str} | ğŸ‘‘=å¤§ä½¬ | ğŸŒ=æœ‰è·¨ç•Œè®¨è®º\n\n"
    md_content += "| å¢é•¿/h | æ™ºèƒ½æ ‡ç­¾ | é¡¹ç›®åç§° | æ€» Stars | è·¨ç•Œè®¨è®º | ä¸­æ–‡ç®€ä»‹ |\n| :--- | :--- | :--- | :--- | :--- | :--- |\n"
    
    for i in sorted_items[:15]:
        growth_style = f"**ğŸ”¥ +{i['raw_growth']}**" if i['raw_growth'] >= GROWTH_THRESHOLD else f"+{i['raw_growth']}"
        desc_zh = translate_to_zh(i['description'])
        hn_link = f"[ğŸ’¬è®¨è®º]({i['hn_info']['url']})" if i.get('hn_info') else "--"
        md_content += f"| {growth_style} | {i['smart_tags']} | [{i['full_name']}]({i['html_url']}) | {i['stargazers_count']} | {hn_link} | {desc_zh} |\n"

    with open("README.md", "w", encoding="utf-8") as f: f.write(md_content)

    # --- 6. é£ä¹¦å¡ç‰‡æ¨é€ ---
    SUMMARY_HOURS = [9, 21]  
    is_summary_time = now.hour in SUMMARY_HOURS

    if is_summary_time:
        push_candidates = sorted_items[:8]
        card_title, card_template, status_prefix = "ğŸ“Š GitHub è¶‹åŠ¿æ±‡æ€»", "blue", "ğŸ“ˆ Top"
    else:
        push_candidates = (explosive_items + [i for i in new_items if i not in explosive_items])[:5]
        card_title = "ğŸ›°ï¸ é¡¶çº§æŠ€æœ¯æƒ…æŠ¥"
        is_fame = push_candidates[0].get('fame_tag') if push_candidates else False
        card_template, status_prefix = ("purple" if is_fame else "orange"), ""

    if push_candidates and FEISHU_WEBHOOK:
        card_elements = []
        for idx, i in enumerate(push_candidates):
            desc_zh = translate_to_zh(i['description'])
            growth_info = f"\nğŸš€ **æ—¶é€Ÿ: +{i['raw_growth']} stars/hr**" if i['raw_growth'] > 0 else ""
            hn_text = f"\nğŸŒ **HNè®¨è®º**: [{i['hn_info']['points']}åˆ†/{i['hn_info']['comments']}è¯„]({i['hn_info']['url']})" if i.get('hn_info') else ""
            
            if is_summary_time: status = f"{status_prefix} {idx+1}"
            else: status = "ğŸš¨ å¤§ä½¬åŠ¨å‘" if i['fame_tag'] else ("ğŸ”´ ç‰¹æ€¥çˆ†å‘" if i['raw_growth'] >= GROWTH_THRESHOLD else "âœ¨ å‘ç°æ–°é¡¹ç›®")
            
            card_elements.append({
                "tag": "div",
                "text": {"tag": "lark_md", "content": f"**{status}** | {i['smart_tags']}\n**é¡¹ç›®**: [{i['full_name']}]({i['html_url']})\n**æ€» Stars**: `{i['stargazers_count']}`{growth_info}{hn_text}\n**ç®€ä»‹**: {desc_zh}"}
            })
            card_elements.append({"tag": "hr"})

        requests.post(FEISHU_WEBHOOK, json={
            "msg_type": "interactive",
            "card": {
                "header": {"title": {"tag": "plain_text", "content": card_title}, "template": card_template},
                "elements": card_elements
            }
        })

    # --- 7. æŒä¹…åŒ– ---
    for i in new_items: pushed_ids.add(str(i['id']))
    with open(DB_FILE, "w") as f:
        for _id in pushed_ids: f.write(f"{_id}\n")
    with open(HISTORY_FILE, "w") as f:
        json.dump(current_stars_map, f)

except Exception as e:
    print(f"è¿è¡Œå‡ºé”™: {e}")
